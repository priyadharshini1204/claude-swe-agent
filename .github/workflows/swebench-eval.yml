
name: SWE-Bench Evaluation Workflow

on:
  push:
    branches:
      - main
  workflow_dispatch:

permissions:
  contents: write

jobs:
  swe-bench-eval:
    runs-on: ubuntu-latest
    container:
      image: manojva/openlibrary-python312:latest
      options: --user root

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Install Agent Dependencies
        run: |
          pip install requests pyyaml

      - name: Setup Target Repository
        run: |
          rm -rf /testbed
          git clone https://github.com/internetarchive/openlibrary.git /testbed
          cd /testbed
          git config --global --add safe.directory /testbed
          git reset --hard 84cc4ed5697b83a849e9106a09bfed501169cc20

      - name: Run AI Agent (Claude)
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          python run_claude.py

      - name: Extract Metrics
        if: always()
        run: |
          python extract_metrics.py

      - name: Upload Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: evaluation-artifacts
          path: |
            agent.log
            result.json
            pre_verification.log
            post_verification.log
            changes.patch
            prompts.log
            prompts.md
